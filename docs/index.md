## Distributed Training

The goal of distributed training of deep learning modelsâ€”to significantly **reduce the training time** of deep learning models without degrading their performance.

#### Pipelines

![dist](SDTL.png)


## Benchmarks

#### 4 workers (1 Server and 4 GTX-1080 on a single server)

![result1](result1.png)

#### 12 workers (3 Servers and 4 GTX-1080 on a single server)

![result2](result2.png)
